# ECI Extraction Pipeline

Data processing pipeline that transforms raw HTML scraped from the **European Citizens' Initiatives (ECI)** registry into structured, analytical datasets (CSV).

## ğŸ“‹ Extractors (Run in Sequence)

The extraction modules process data in the same order as the scrapers, building upon the previous steps' outputs.

| Module | Purpose | Source Data | Key Output |
|--------|---------|-------------|------------|
| `initiatives` | Structured metadata & signature counts | `initiatives/` HTML | `eci_initiatives_{TIMESTAMP}.csv` |
| `responses` | Legislative analysis of Commission answers | `responses/` HTML | `eci_responses_{TIMESTAMP}.csv` |
| `responses_followup_website` | Deep-dive into dedicated follow-up pages | `responses_followup_website/` HTML | `eci_responses_followup_website_{TIMESTAMP}.csv` |

## ğŸ§ª Testing

Each extractor module includes its own comprehensive **pytest suite** located in its `tests/` subdirectory:

- **`initiatives/tests/`**: Behavioral tests for metadata extraction, registration numbers, titles, objectives, timelines, signatures, organizers, and CSV processing.
- **`responses/tests/`**: Tests for legislative outcome classification, rejection reason parsing, and response data extraction.
- **`responses_followup_website/tests/`**: Tests for follow-up event detection, implementation tracking, and complex text analysis.

### Running Tests

From the project root, use the `run_tests.py` script:

```bash
# Run all extractor tests
python run_tests.py --extractor

# Run specific component tests
python run_tests.py --extractor --initiatives
python run_tests.py --extractor --responses
python run_tests.py --extractor --followup-website

# Run with specific test types
python run_tests.py --extractor --initiatives --behaviour
python run_tests.py --extractor --responses --end-to-end

# Run with verbose output and coverage
python run_tests.py --extractor --coverage -v
```

### Direct pytest Usage

You can also run tests directly with pytest:

```bash
# All extractor tests
pytest ECI_initiatives/data_pipeline/extractor

# Specific module tests
pytest ECI_initiatives/data_pipeline/extractor/initiatives/tests
pytest ECI_initiatives/data_pipeline/extractor/responses/tests
pytest ECI_initiatives/data_pipeline/extractor/responses_followup_website/tests
```

## ğŸ› ï¸ Prerequisites

- **Python 3.8+**
- Dependencies: `pip install -r ECI_initiatives/data_pipeline/requirements.prod.txt`
  - Key library: **BeautifulSoup4** (for parsing)
- Test dependencies: `pip install -r ECI_initiatives/tests/requirements.test.txt`

## ğŸš€ Quick Start

Ensure you have already run the **Scraper Pipeline** so that the `data/` directory contains raw HTML files.

```bash
cd ECI_initiatives
uv venv && uv pip install -r data_pipeline/requirements.prod.txt
source .venv/bin/activate  # Linux/macOS
# Windows: .venv\Scripts\activate

# Run pipeline sequentially
# Each step automatically detects the latest timestamped data folder

python -m data_pipeline.extractor.initiatives
python -m data_pipeline.extractor.responses
python -m data_pipeline.extractor.responses_followup_website
```

## ğŸ“¦ Data Pipeline Flow

The extractors read raw HTML from subdirectories and output enriched CSVs into the **same** timestamped run folder to keep input/output bundled together.

```text
data/YYYY-MM-DD_HH-MM-SS/
â”œâ”€â”€ initiatives/                 # [INPUT] Raw HTML
â”œâ”€â”€ responses/                   # [INPUT] Raw HTML
â”œâ”€â”€ responses_followup_website/  # [INPUT] Raw HTML
â”‚
â”œâ”€â”€ eci_initiatives_....csv      # [OUTPUT] Metadata, signatures, funding
â”œâ”€â”€ eci_responses_....csv        # [OUTPUT] Legislative status, rejection reasons
â””â”€â”€ eci_responses_followup_....csv # [OUTPUT] Implementation details, events
```

## ğŸ”— Dependencies

The extractor modules have the following dependencies:

1. **`initiatives`**: Requires scraped HTML from `scraper.initiatives`
2. **`responses`**: Requires:
   - Scraped HTML from `scraper.responses`
   - `eci_initiatives_*.csv` from `extractor.initiatives` (for validation)
3. **`responses_followup_website`**: Requires:
   - Scraped HTML from `scraper.responses_followup_website`
   - `eci_responses_*.csv` from `extractor.responses` (for validation and metadata)

**For detailed module documentation:**

- [Initiatives Extractor](./initiatives/README.ex_initiatives.md)
- [Responses Extractor](./responses/README.ex_responses.md)
- [Follow-up Website Extractor](./responses_followup_website/README.ex_followup.md)